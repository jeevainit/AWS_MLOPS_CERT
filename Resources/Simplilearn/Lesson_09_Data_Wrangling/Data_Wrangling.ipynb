{"cells":[{"cell_type":"markdown","id":"6b8fa3be-89f4-4947-83ce-163b74237c7f","metadata":{"id":"6b8fa3be-89f4-4947-83ce-163b74237c7f"},"source":["# __Data Wrangling__"]},{"cell_type":"markdown","id":"72278e90-5b62-4e4c-9783-13c8de00eac4","metadata":{"id":"72278e90-5b62-4e4c-9783-13c8de00eac4"},"source":["## __Agenda__"]},{"cell_type":"markdown","id":"40382cae-3528-4cde-8b67-71c2312017fc","metadata":{"id":"40382cae-3528-4cde-8b67-71c2312017fc"},"source":["In this lesson, we will cover the following concepts with the help of examples:\n","- Introduction to data wrangling\n","- Data collection\n","- Data inspection\n","  * Accessing rows using .iloc and .loc\n","  * Checking for missing values\n","  * Handling missing data\n","- Dealing with duplicates\n","- Data cleaning\n","- Data transformation\n","- Data binning\n","- Handling outliers\n","- Pandas joining techniques\n","    * Pandas concatenate\n","    * Pandas merge dataframes\n","    * Pandas join dataframes\n","- Aggregating data\n","- Reshaping data"]},{"cell_type":"markdown","id":"945bea75-2b82-48fd-bce8-d938dac2225f","metadata":{"id":"945bea75-2b82-48fd-bce8-d938dac2225f"},"source":["## __1. Introduction to Data Wrangling__\n","Data wrangling, also known as data munging or data preprocessing, is the process of cleaning, structuring, and transforming raw data into a format suitable for analysis.\n","- It is a crucial step in the data preparation pipeline, aiming to make the data more accessible, understandable, and ready for various analytical tasks.\n","- It involves dealing with missing values, handling outliers, transforming variables, and merging datasets, among other tasks."]},{"cell_type":"markdown","id":"114565c7-e82d-4fd4-8284-f110283e346d","metadata":{"id":"114565c7-e82d-4fd4-8284-f110283e346d"},"source":["![link text](https://labcontent.simplicdn.net/data-content/content-assets/Data_and_AI/ADSP_Images/Lesson_09_Data_Wrangling/Introduction.png)"]},{"cell_type":"markdown","id":"7dbc5dc1-ef65-41f7-825b-2c8f3105d965","metadata":{"id":"7dbc5dc1-ef65-41f7-825b-2c8f3105d965"},"source":["## __2. Data Collection:__\n","\n","Data collection is the process of gathering information from diverse sources to build a comprehensive dataset for analysis.\n","- Sources may include databases, APIs (Application Programming Interfaces), spreadsheets, or external files. Effective data collection ensures the availability of relevant and reliable information."]},{"cell_type":"markdown","id":"5f48feae-dfed-4fd1-bcc7-bac222ce1e65","metadata":{"id":"5f48feae-dfed-4fd1-bcc7-bac222ce1e65"},"source":["### __Loading Data:__\n","Start by loading data into a Pandas DataFrame"]},{"cell_type":"markdown","id":"00c0da67-9f48-46b8-8ce4-3291cdd54eba","metadata":{"id":"00c0da67-9f48-46b8-8ce4-3291cdd54eba"},"source":["![link text](https://labcontent.simplicdn.net/data-content/content-assets/Data_and_AI/ADSP_Images/Lesson_09_Data_Wrangling/Loading.png)"]},{"cell_type":"code","execution_count":null,"id":"c17ac73f-5252-43e5-ba66-21d40e15d075","metadata":{"id":"c17ac73f-5252-43e5-ba66-21d40e15d075"},"outputs":[],"source":["import pandas as pd\n","\n","# Load the data\n","df = pd.read_csv('HousePrices.csv')"]},{"cell_type":"markdown","id":"10b89993-0daa-4cd1-8023-c43c6ca0cb9d","metadata":{"id":"10b89993-0daa-4cd1-8023-c43c6ca0cb9d"},"source":["## __3. Data Inspection__\n","It involves exploring the dataset to gain insights into its structure and quality.\n","- This step involves using functions like df.head(), df.info(), and df.describe() to gain insights into the dataset's structure, data types, and statistical summaries. Checking for missing values, outliers, and inconsistencies is crucial to identify potential issues that need addressing."]},{"cell_type":"code","execution_count":null,"id":"1d5d0f7e-4a54-4534-b2c0-8a36531abda2","metadata":{"id":"1d5d0f7e-4a54-4534-b2c0-8a36531abda2","outputId":"ededa4a8-4cdc-4410-84a3-b18cb85b2d60"},"outputs":[{"name":"stdout","output_type":"stream","text":["                  date      price  bedrooms  bathrooms  sqft_living  sqft_lot  \\\n","0  2014-05-02 00:00:00   313000.0       3.0       1.50         1340      7912   \n","1  2014-05-02 00:00:00  2384000.0       5.0       2.50         3650      9050   \n","2  2014-05-02 00:00:00   342000.0       3.0       2.00         1930     11947   \n","3  2014-05-02 00:00:00   420000.0       3.0       2.25         2000      8030   \n","4  2014-05-02 00:00:00   550000.0       4.0       2.50         1940     10500   \n","\n","   floors  waterfront  view  condition  sqft_above  sqft_basement  yr_built  \\\n","0     1.5           0     0          3        1340              0      1955   \n","1     2.0           0     4          5        3370            280      1921   \n","2     1.0           0     0          4        1930              0      1966   \n","3     1.0           0     0          4        1000           1000      1963   \n","4     1.0           0     0          4        1140            800      1976   \n","\n","   yr_renovated                    street       city  statezip country  \n","0          2005      18810 Densmore Ave N  Shoreline  WA 98133     USA  \n","1             0           709 W Blaine St    Seattle  WA 98119     USA  \n","2             0  26206-26214 143rd Ave SE       Kent  WA 98042     USA  \n","3             0           857 170th Pl NE   Bellevue  WA 98008     USA  \n","4          1992         9105 170th Ave NE    Redmond  WA 98052     USA  \n","                     date          price  bedrooms  bathrooms  sqft_living  \\\n","4595  2014-07-09 00:00:00  308166.666667       3.0       1.75         1510   \n","4596  2014-07-09 00:00:00  534333.333333       3.0       2.50         1460   \n","4597  2014-07-09 00:00:00  416904.166667       3.0       2.50         3010   \n","4598  2014-07-10 00:00:00  203400.000000       4.0       2.00         2090   \n","4599  2014-07-10 00:00:00  220600.000000       3.0       2.50         1490   \n","\n","      sqft_lot  floors  waterfront  view  condition  sqft_above  \\\n","4595      6360     1.0           0     0          4        1510   \n","4596      7573     2.0           0     0          3        1460   \n","4597      7014     2.0           0     0          3        3010   \n","4598      6630     1.0           0     0          3        1070   \n","4599      8102     2.0           0     0          4        1490   \n","\n","      sqft_basement  yr_built  yr_renovated             street       city  \\\n","4595              0      1954          1979     501 N 143rd St    Seattle   \n","4596              0      1983          2009   14855 SE 10th Pl   Bellevue   \n","4597              0      2009             0   759 Ilwaco Pl NE     Renton   \n","4598           1020      1974             0  5148 S Creston St    Seattle   \n","4599              0      1990             0  18717 SE 258th St  Covington   \n","\n","      statezip country  \n","4595  WA 98133     USA  \n","4596  WA 98007     USA  \n","4597  WA 98059     USA  \n","4598  WA 98178     USA  \n","4599  WA 98042     USA  \n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 4600 entries, 0 to 4599\n","Data columns (total 18 columns):\n"," #   Column         Non-Null Count  Dtype  \n","---  ------         --------------  -----  \n"," 0   date           4600 non-null   object \n"," 1   price          4600 non-null   float64\n"," 2   bedrooms       4600 non-null   float64\n"," 3   bathrooms      4600 non-null   float64\n"," 4   sqft_living    4600 non-null   int64  \n"," 5   sqft_lot       4600 non-null   int64  \n"," 6   floors         4600 non-null   float64\n"," 7   waterfront     4600 non-null   int64  \n"," 8   view           4600 non-null   int64  \n"," 9   condition      4600 non-null   int64  \n"," 10  sqft_above     4600 non-null   int64  \n"," 11  sqft_basement  4600 non-null   int64  \n"," 12  yr_built       4600 non-null   int64  \n"," 13  yr_renovated   4600 non-null   int64  \n"," 14  street         4600 non-null   object \n"," 15  city           4600 non-null   object \n"," 16  statezip       4600 non-null   object \n"," 17  country        4600 non-null   object \n","dtypes: float64(4), int64(9), object(5)\n","memory usage: 647.0+ KB\n","None\n","              price     bedrooms    bathrooms   sqft_living      sqft_lot  \\\n","count  4.600000e+03  4600.000000  4600.000000   4600.000000  4.600000e+03   \n","mean   5.519630e+05     3.400870     2.160815   2139.346957  1.485252e+04   \n","std    5.638347e+05     0.908848     0.783781    963.206916  3.588444e+04   \n","min    0.000000e+00     0.000000     0.000000    370.000000  6.380000e+02   \n","25%    3.228750e+05     3.000000     1.750000   1460.000000  5.000750e+03   \n","50%    4.609435e+05     3.000000     2.250000   1980.000000  7.683000e+03   \n","75%    6.549625e+05     4.000000     2.500000   2620.000000  1.100125e+04   \n","max    2.659000e+07     9.000000     8.000000  13540.000000  1.074218e+06   \n","\n","            floors   waterfront         view    condition   sqft_above  \\\n","count  4600.000000  4600.000000  4600.000000  4600.000000  4600.000000   \n","mean      1.512065     0.007174     0.240652     3.451739  1827.265435   \n","std       0.538288     0.084404     0.778405     0.677230   862.168977   \n","min       1.000000     0.000000     0.000000     1.000000   370.000000   \n","25%       1.000000     0.000000     0.000000     3.000000  1190.000000   \n","50%       1.500000     0.000000     0.000000     3.000000  1590.000000   \n","75%       2.000000     0.000000     0.000000     4.000000  2300.000000   \n","max       3.500000     1.000000     4.000000     5.000000  9410.000000   \n","\n","       sqft_basement     yr_built  yr_renovated  \n","count    4600.000000  4600.000000   4600.000000  \n","mean      312.081522  1970.786304    808.608261  \n","std       464.137228    29.731848    979.414536  \n","min         0.000000  1900.000000      0.000000  \n","25%         0.000000  1951.000000      0.000000  \n","50%         0.000000  1976.000000      0.000000  \n","75%       610.000000  1997.000000   1999.000000  \n","max      4820.000000  2014.000000   2014.000000  \n"]},{"data":{"text/plain":["date              object\n","price            float64\n","bedrooms         float64\n","bathrooms        float64\n","sqft_living        int64\n","sqft_lot           int64\n","floors           float64\n","waterfront         int64\n","view               int64\n","condition          int64\n","sqft_above         int64\n","sqft_basement      int64\n","yr_built           int64\n","yr_renovated       int64\n","street            object\n","city              object\n","statezip          object\n","country           object\n","dtype: object"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["# Inspecting the first few rows of the DataFrame\n","print(df.head())\n","\n","# Displaying the last few rows of the DataFrame\n","print(df.tail())\n","\n","# Providing information about the DataFrame, including data types and non-null counts\n","print(df.info())\n","\n","# Displaying descriptive statistics of the DataFrame, such as mean, std, min, max, etc.\n","print(df.describe())\n","\n","# Displaying datatypes of the columns\n","df.dtypes"]},{"cell_type":"markdown","id":"64bb0950-d529-42bb-9c33-ca7c37162d23","metadata":{"id":"64bb0950-d529-42bb-9c33-ca7c37162d23"},"source":["### __3.1 Accessing Rows Using .iloc and .loc__\n","Inspecting the dataset involves exploring its content.\n","- Using .iloc and .loc allows you to access specific rows based on integer-location or label-based indexing, respectively."]},{"cell_type":"code","execution_count":null,"id":"564bb6a1-34c3-4a52-8cc8-a1f108c73923","metadata":{"id":"564bb6a1-34c3-4a52-8cc8-a1f108c73923","outputId":"b749bd48-23e2-4f11-f4cd-2a6a82364867"},"outputs":[{"name":"stdout","output_type":"stream","text":["Result for df.iloc[0]:\n","date              2014-05-02 00:00:00\n","price                        313000.0\n","bedrooms                          3.0\n","bathrooms                         1.5\n","sqft_living                      1340\n","sqft_lot                         7912\n","floors                            1.5\n","waterfront                          0\n","view                                0\n","condition                           3\n","sqft_above                       1340\n","sqft_basement                       0\n","yr_built                         1955\n","yr_renovated                     2005\n","street           18810 Densmore Ave N\n","city                        Shoreline\n","statezip                     WA 98133\n","country                           USA\n","Name: 0, dtype: object\n","\n","Result for df.iloc[10]:\n","date             2014-05-02 00:00:00\n","price                       463000.0\n","bedrooms                         3.0\n","bathrooms                       1.75\n","sqft_living                     1710\n","sqft_lot                        7320\n","floors                           1.0\n","waterfront                         0\n","view                               0\n","condition                          3\n","sqft_above                      1710\n","sqft_basement                      0\n","yr_built                        1948\n","yr_renovated                    1994\n","street            Burke-Gilman Trail\n","city                Lake Forest Park\n","statezip                    WA 98155\n","country                          USA\n","Name: 10, dtype: object\n"]}],"source":["# Access the first row using iloc\n","result_iloc_0 = df.iloc[0]\n","\n","# Display the result for df.iloc[0]\n","print(\"Result for df.iloc[0]:\")\n","print(result_iloc_0)\n","print()\n","\n","# Access the eleventh row using iloc\n","result_iloc_10 = df.iloc[10]\n","\n","# Display the result for df.iloc[10]\n","print(\"Result for df.iloc[10]:\")\n","print(result_iloc_10)\n"]},{"cell_type":"markdown","id":"871a7c95-b6b5-4c77-b1eb-6b666eff4403","metadata":{"id":"871a7c95-b6b5-4c77-b1eb-6b666eff4403"},"source":["### __3.2 Checking for Missing Values__\n","![link text](https://labcontent.simplicdn.net/data-content/content-assets/Data_and_AI/ADSP_Images/Lesson_09_Data_Wrangling/Checking_for_missing_values.png)"]},{"cell_type":"code","execution_count":null,"id":"60b83ed8-4871-434d-be6c-bddb84c5d3c5","metadata":{"id":"60b83ed8-4871-434d-be6c-bddb84c5d3c5","outputId":"247cdf90-2d96-4a8b-b11e-c5a731abd660"},"outputs":[{"name":"stdout","output_type":"stream","text":["Missing Values per Column:\n","date             0\n","price            0\n","bedrooms         0\n","bathrooms        0\n","sqft_living      0\n","sqft_lot         0\n","floors           0\n","waterfront       0\n","view             0\n","condition        0\n","sqft_above       0\n","sqft_basement    0\n","yr_built         0\n","yr_renovated     0\n","street           0\n","city             0\n","statezip         0\n","country          0\n","dtype: int64\n"]}],"source":["# Checking for missing values\n","missing_values = df.isnull().sum()\n","print(\"Missing Values per Column:\")\n","print(missing_values)"]},{"cell_type":"markdown","id":"f1d116c3-c39c-4442-a791-656739b579c0","metadata":{"id":"f1d116c3-c39c-4442-a791-656739b579c0"},"source":["### __3.3 Handling Missing Data__\n","Handling missing data is crucial for maintaining data integrity. Various approaches include imputation (replacing missing values with estimated values), the removal of records with missing values, or using default values when appropriate.\n","![link text](https://labcontent.simplicdn.net/data-content/content-assets/Data_and_AI/ADSP_Images/Lesson_09_Data_Wrangling/Handling_missing_data.png)"]},{"cell_type":"markdown","id":"089fb326-1568-47de-8b59-f3e52a06992c","metadata":{"id":"089fb326-1568-47de-8b59-f3e52a06992c"},"source":["To handle missing values in numerical columns of the dataset, we utilize `iloc` to select them, excluding text columns. Thus, we focus solely on columns 1 to 14, which do not contain text data."]},{"cell_type":"code","execution_count":null,"id":"8cd59b6a-7996-4afd-9a5e-de7b7c509c3b","metadata":{"id":"8cd59b6a-7996-4afd-9a5e-de7b7c509c3b","outputId":"b7559f29-febc-4bea-e8c3-5fbfbb723e14","tags":[]},"outputs":[{"ename":"NameError","evalue":"name 'df' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Handling missing values using imputation\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df_filled \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mfillna(df\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m14\u001b[39m]\u001b[38;5;241m.\u001b[39mmean())\n","\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"]}],"source":["# Handling missing values using imputation\n","df_filled = df.fillna(df.iloc[:, 1:14].mean())"]},{"cell_type":"markdown","id":"207d4f88-4ff6-4f86-8037-3e1241168157","metadata":{"id":"207d4f88-4ff6-4f86-8037-3e1241168157"},"source":["## __4. Dealing with Duplicates__\n","\n","Duplicates in a dataset can introduce bias and errors.\n","- Identifying and handling duplicate records is essential to ensuring accurate analysis and reporting.\n","\n","![link text](https://labcontent.simplicdn.net/data-content/content-assets/Data_and_AI/ADSP_Images/Lesson_09_Data_Wrangling/Dealing_with_duplicates.png)"]},{"cell_type":"code","execution_count":null,"id":"f56205a2-53a6-40ca-9207-c7c453cb8208","metadata":{"id":"f56205a2-53a6-40ca-9207-c7c453cb8208"},"outputs":[],"source":["# Removing duplicate records\n","df_no_duplicates = df.drop_duplicates()"]},{"cell_type":"markdown","id":"a8e3791d","metadata":{"id":"a8e3791d"},"source":["By default, __drop_duplicates()__ retains the first occurrence and eliminates subsequent duplicates, unless instructed otherwise using the `keep` parameter."]},{"cell_type":"markdown","id":"f606a020-a1a9-4ba6-a8bb-46d86bcb384d","metadata":{"id":"f606a020-a1a9-4ba6-a8bb-46d86bcb384d"},"source":["## __5. Data Cleaning__\n","\n","This includes correcting typographical errors, standardizing date formats, and resolving inconsistencies in categorical data labeling.\n","- Standardizing data formats and units ensures consistency and facilitates analysis."]},{"cell_type":"code","execution_count":null,"id":"1a1e06d9-42a4-4845-9ba2-2cdb515a303b","metadata":{"id":"1a1e06d9-42a4-4845-9ba2-2cdb515a303b","outputId":"8bf9c7af-78ae-4f09-b804-58ab2b4df363"},"outputs":[{"name":"stdout","output_type":"stream","text":["DataFrame after cleaning data by standardizing formats:\n","           date         price  bedrooms  bathrooms  sqft_living  sqft_lot  \\\n","0    2014-05-02  3.130000e+05       3.0       1.50         1340      7912   \n","1    2014-05-02  2.384000e+06       5.0       2.50         3650      9050   \n","2    2014-05-02  3.420000e+05       3.0       2.00         1930     11947   \n","3    2014-05-02  4.200000e+05       3.0       2.25         2000      8030   \n","4    2014-05-02  5.500000e+05       4.0       2.50         1940     10500   \n","...         ...           ...       ...        ...          ...       ...   \n","4595 2014-07-09  3.081667e+05       3.0       1.75         1510      6360   \n","4596 2014-07-09  5.343333e+05       3.0       2.50         1460      7573   \n","4597 2014-07-09  4.169042e+05       3.0       2.50         3010      7014   \n","4598 2014-07-10  2.034000e+05       4.0       2.00         2090      6630   \n","4599 2014-07-10  2.206000e+05       3.0       2.50         1490      8102   \n","\n","      floors  waterfront  view  condition  sqft_above  sqft_basement  \\\n","0        1.5           0     0          3        1340              0   \n","1        2.0           0     4          5        3370            280   \n","2        1.0           0     0          4        1930              0   \n","3        1.0           0     0          4        1000           1000   \n","4        1.0           0     0          4        1140            800   \n","...      ...         ...   ...        ...         ...            ...   \n","4595     1.0           0     0          4        1510              0   \n","4596     2.0           0     0          3        1460              0   \n","4597     2.0           0     0          3        3010              0   \n","4598     1.0           0     0          3        1070           1020   \n","4599     2.0           0     0          4        1490              0   \n","\n","      yr_built  yr_renovated                    street       city  statezip  \\\n","0         1955          2005      18810 Densmore Ave N  Shoreline  WA 98133   \n","1         1921             0           709 W Blaine St    Seattle  WA 98119   \n","2         1966             0  26206-26214 143rd Ave SE       Kent  WA 98042   \n","3         1963             0           857 170th Pl NE   Bellevue  WA 98008   \n","4         1976          1992         9105 170th Ave NE    Redmond  WA 98052   \n","...        ...           ...                       ...        ...       ...   \n","4595      1954          1979            501 N 143rd St    Seattle  WA 98133   \n","4596      1983          2009          14855 SE 10th Pl   Bellevue  WA 98007   \n","4597      2009             0          759 Ilwaco Pl NE     Renton  WA 98059   \n","4598      1974             0         5148 S Creston St    Seattle  WA 98178   \n","4599      1990             0         18717 SE 258th St  Covington  WA 98042   \n","\n","     country  \n","0        USA  \n","1        USA  \n","2        USA  \n","3        USA  \n","4        USA  \n","...      ...  \n","4595     USA  \n","4596     USA  \n","4597     USA  \n","4598     USA  \n","4599     USA  \n","\n","[4600 rows x 18 columns]\n"]}],"source":["# Cleaning data by standardizing formats\n","df['date'] = pd.to_datetime(df['date'])\n","# Displaying the DataFrame after cleaning\n","print(\"DataFrame after cleaning data by standardizing formats:\")\n","print(df)"]},{"cell_type":"markdown","id":"2bee3e01-85d1-49c4-b598-6faa4a0e13ae","metadata":{"id":"2bee3e01-85d1-49c4-b598-6faa4a0e13ae"},"source":["## __6. Data Transformation__\n","\n","Data transformation includes converting data types, creating new features through feature engineering, and normalizing or scaling numeric values as needed."]},{"cell_type":"code","execution_count":null,"id":"1f9034ee-a8e8-4bbf-9564-3ebba6ae992f","metadata":{"id":"1f9034ee-a8e8-4bbf-9564-3ebba6ae992f","outputId":"f0196368-1490-467b-afe0-2238a8d67704"},"outputs":[{"name":"stdout","output_type":"stream","text":["DataFrame with new features:\n","           date         price  bedrooms  bathrooms  sqft_living  sqft_lot  \\\n","0    2014-05-02  3.130000e+05       3.0       1.50         1340      7912   \n","1    2014-05-02  2.384000e+06       5.0       2.50         3650      9050   \n","2    2014-05-02  3.420000e+05       3.0       2.00         1930     11947   \n","3    2014-05-02  4.200000e+05       3.0       2.25         2000      8030   \n","4    2014-05-02  5.500000e+05       4.0       2.50         1940     10500   \n","...         ...           ...       ...        ...          ...       ...   \n","4595 2014-07-09  3.081667e+05       3.0       1.75         1510      6360   \n","4596 2014-07-09  5.343333e+05       3.0       2.50         1460      7573   \n","4597 2014-07-09  4.169042e+05       3.0       2.50         3010      7014   \n","4598 2014-07-10  2.034000e+05       4.0       2.00         2090      6630   \n","4599 2014-07-10  2.206000e+05       3.0       2.50         1490      8102   \n","\n","      floors  waterfront  view  condition  sqft_above  sqft_basement  \\\n","0        1.5           0     0          3        1340              0   \n","1        2.0           0     4          5        3370            280   \n","2        1.0           0     0          4        1930              0   \n","3        1.0           0     0          4        1000           1000   \n","4        1.0           0     0          4        1140            800   \n","...      ...         ...   ...        ...         ...            ...   \n","4595     1.0           0     0          4        1510              0   \n","4596     2.0           0     0          3        1460              0   \n","4597     2.0           0     0          3        3010              0   \n","4598     1.0           0     0          3        1070           1020   \n","4599     2.0           0     0          4        1490              0   \n","\n","      yr_built  yr_renovated                    street       city  statezip  \\\n","0         1955          2005      18810 Densmore Ave N  Shoreline  WA 98133   \n","1         1921             0           709 W Blaine St    Seattle  WA 98119   \n","2         1966             0  26206-26214 143rd Ave SE       Kent  WA 98042   \n","3         1963             0           857 170th Pl NE   Bellevue  WA 98008   \n","4         1976          1992         9105 170th Ave NE    Redmond  WA 98052   \n","...        ...           ...                       ...        ...       ...   \n","4595      1954          1979            501 N 143rd St    Seattle  WA 98133   \n","4596      1983          2009          14855 SE 10th Pl   Bellevue  WA 98007   \n","4597      2009             0          759 Ilwaco Pl NE     Renton  WA 98059   \n","4598      1974             0         5148 S Creston St    Seattle  WA 98178   \n","4599      1990             0         18717 SE 258th St  Covington  WA 98042   \n","\n","     country  Log_Price  Normalized_Price  \n","0        USA  12.653958          0.011771  \n","1        USA  14.684290          0.089658  \n","2        USA  12.742566          0.012862  \n","3        USA  12.948010          0.015795  \n","4        USA  13.217674          0.020684  \n","...      ...        ...               ...  \n","4595     USA  12.638396          0.011590  \n","4596     USA  13.188775          0.020095  \n","4597     USA  12.940612          0.015679  \n","4598     USA  12.222930          0.007649  \n","4599     USA  12.304106          0.008296  \n","\n","[4600 rows x 20 columns]\n"]}],"source":["# Creating a new feature and normalizing numeric values\n","# Check if 'price' column exists in the DataFrame\n","import numpy as np\n","if 'price' in df.columns:\n","    # Use the natural logarithm to create a new feature 'Log_Price'\n","    df['Log_Price'] = df['price'].apply(lambda x: np.log(x))\n","\n","    # Normalize 'price' column and create a new feature 'Normalized_Price'\n","    df['Normalized_Price'] = (df['price'] - df['price'].min()) / (df['price'].max() - df['price'].min())\n","\n","    # Displaying the DataFrame with the new features\n","    print(\"DataFrame with new features:\")\n","    print(df)\n","else:\n","    print(\"The 'price' column does not exist in the DataFrame.\")"]},{"cell_type":"markdown","id":"1ee6cb49-8f47-4f7e-89a7-973ca1e2c940","metadata":{"id":"1ee6cb49-8f47-4f7e-89a7-973ca1e2c940"},"source":["## __7. Data Binning__\n","Data binning, also known as discretization, is a technique in data transformation to convert continuous numerical data into discrete bins or intervals.\n","- This process helps simplify the analysis of trends, handle outliers, and make data more suitable for certain types of analyses or machine learning algorithms.\n","- It involves grouping numeric values into predefined ranges, creating a categorical representation of the data."]},{"cell_type":"code","execution_count":null,"id":"70655820-f5ee-406c-9972-c4c689380dd8","metadata":{"id":"70655820-f5ee-406c-9972-c4c689380dd8","outputId":"c8fc707d-09b1-43b8-e471-39b22e8ef303"},"outputs":[{"name":"stdout","output_type":"stream","text":["DataFrame with Price_Category column:\n","           date         price  bedrooms  bathrooms  sqft_living  sqft_lot  \\\n","0    2014-05-02  3.130000e+05       3.0       1.50         1340      7912   \n","1    2014-05-02  2.384000e+06       5.0       2.50         3650      9050   \n","2    2014-05-02  3.420000e+05       3.0       2.00         1930     11947   \n","3    2014-05-02  4.200000e+05       3.0       2.25         2000      8030   \n","4    2014-05-02  5.500000e+05       4.0       2.50         1940     10500   \n","...         ...           ...       ...        ...          ...       ...   \n","4595 2014-07-09  3.081667e+05       3.0       1.75         1510      6360   \n","4596 2014-07-09  5.343333e+05       3.0       2.50         1460      7573   \n","4597 2014-07-09  4.169042e+05       3.0       2.50         3010      7014   \n","4598 2014-07-10  2.034000e+05       4.0       2.00         2090      6630   \n","4599 2014-07-10  2.206000e+05       3.0       2.50         1490      8102   \n","\n","      floors  waterfront  view  condition  ...  sqft_basement  yr_built  \\\n","0        1.5           0     0          3  ...              0      1955   \n","1        2.0           0     4          5  ...            280      1921   \n","2        1.0           0     0          4  ...              0      1966   \n","3        1.0           0     0          4  ...           1000      1963   \n","4        1.0           0     0          4  ...            800      1976   \n","...      ...         ...   ...        ...  ...            ...       ...   \n","4595     1.0           0     0          4  ...              0      1954   \n","4596     2.0           0     0          3  ...              0      1983   \n","4597     2.0           0     0          3  ...              0      2009   \n","4598     1.0           0     0          3  ...           1020      1974   \n","4599     2.0           0     0          4  ...              0      1990   \n","\n","      yr_renovated                    street       city  statezip country  \\\n","0             2005      18810 Densmore Ave N  Shoreline  WA 98133     USA   \n","1                0           709 W Blaine St    Seattle  WA 98119     USA   \n","2                0  26206-26214 143rd Ave SE       Kent  WA 98042     USA   \n","3                0           857 170th Pl NE   Bellevue  WA 98008     USA   \n","4             1992         9105 170th Ave NE    Redmond  WA 98052     USA   \n","...            ...                       ...        ...       ...     ...   \n","4595          1979            501 N 143rd St    Seattle  WA 98133     USA   \n","4596          2009          14855 SE 10th Pl   Bellevue  WA 98007     USA   \n","4597             0          759 Ilwaco Pl NE     Renton  WA 98059     USA   \n","4598             0         5148 S Creston St    Seattle  WA 98178     USA   \n","4599             0         18717 SE 258th St  Covington  WA 98042     USA   \n","\n","      Log_Price  Normalized_Price  Price_Category  \n","0     12.653958          0.011771            501+  \n","1     14.684290          0.089658            501+  \n","2     12.742566          0.012862            501+  \n","3     12.948010          0.015795            501+  \n","4     13.217674          0.020684            501+  \n","...         ...               ...             ...  \n","4595  12.638396          0.011590            501+  \n","4596  13.188775          0.020095            501+  \n","4597  12.940612          0.015679            501+  \n","4598  12.222930          0.007649            501+  \n","4599  12.304106          0.008296            501+  \n","\n","[4600 rows x 21 columns]\n"]}],"source":["# Data Binning: Creating bins for the 'price' column\n","# Check if 'price' column exists in the DataFrame\n","if 'price' in df.columns:\n","    # Define bin edges\n","    bin_edges = [0, 100, 200, 300, 400, 500, np.inf]  # Adjust bin edges as needed\n","\n","    # Define bin labels\n","    bin_labels = ['0-100', '101-200', '201-300', '301-400', '401-500', '501+']\n","\n","    # Create a new categorical column 'Price_Category' based on binning\n","    df['Price_Category'] = pd.cut(df['price'], bins=bin_edges, labels=bin_labels, right=False)\n","\n","    # Displaying the DataFrame with the new 'Price_Category' column\n","    print(\"DataFrame with Price_Category column:\")\n","    print(df)\n","else:\n","    print(\"The 'price' column does not exist in the DataFrame.\")\n"]},{"cell_type":"markdown","id":"c4db68b9-d94c-42f6-b87f-5e7b87b73584","metadata":{"id":"c4db68b9-d94c-42f6-b87f-5e7b87b73584"},"source":["## __8. Handling Outliers__\n","\n","Outliers can significantly impact analysis and modeling. Identifying and addressing outliers is crucial for maintaining the accuracy of results.\n","\n","**Winsorization:** It is the transformation of statistics by limiting extreme values in the statistical data to reduce the effect of possibly spurious outliers."]},{"cell_type":"code","execution_count":null,"id":"c41a7cae-8caf-494d-a4bb-89f128cb15d1","metadata":{"id":"c41a7cae-8caf-494d-a4bb-89f128cb15d1","outputId":"859f3ff1-e766-4e6f-8a86-810d055ce563","tags":[]},"outputs":[{"ename":"NameError","evalue":"name 'df' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmstats\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m winsorize\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Check if 'price' column exists in the DataFrame\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprice\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# Winsorizing the 'price' column with limits [0.05, 0.05]\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWinsorized_Price\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m winsorize(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprice\u001b[39m\u001b[38;5;124m'\u001b[39m], limits\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0.05\u001b[39m, \u001b[38;5;241m0.05\u001b[39m])\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m# Displaying the DataFrame with the winsorized column\u001b[39;00m\n","\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"]}],"source":["# Handling outliers by winsorizing\n","from scipy.stats.mstats import winsorize\n","\n","# Check if 'price' column exists in the DataFrame\n","if 'price' in df.columns:\n","    # Winsorizing the 'price' column with limits [0.05, 0.05]\n","    df['Winsorized_Price'] = winsorize(df['price'], limits=[0.05, 0.05])\n","\n","    # Displaying the DataFrame with the winsorized column\n","    print(\"DataFrame with winsorized column:\")\n","    print(df)\n","else:\n","    print(\"The 'price' column does not exist in the DataFrame.\")"]},{"cell_type":"markdown","id":"f451b3ac-5ee5-4812-b42a-b8216f86680e","metadata":{"id":"f451b3ac-5ee5-4812-b42a-b8216f86680e"},"source":["## __9. Pandas Joining Techniques__"]},{"cell_type":"markdown","id":"1934fad9-66cc-481b-a4d6-257d2664668e","metadata":{"id":"1934fad9-66cc-481b-a4d6-257d2664668e","tags":[]},"source":["Pandas provides various joining techniques, such as merging, joining, and concatenating, which allow datasets to be combined using one or more keys. Each method has unique behaviors and applications.\n","\n","\n","- **Concatenate**: It appends DataFrames vertically or horizontally, offering a straightforward way to combine datasets with distinct columns or indices without regard for overlapping keys or index values.\n","\n","- **Merge**: It combines DataFrames by aligning columns with shared keys, allowing for detailed control over overlapping column names and the use of multiple keys.\n","\n","- **Join**: It aligns DataFrames based on their index values, making it ideal for coordinating data with corresponding indices.\n","\n","These techniques are essential for integrating and analyzing different datasets. They enable a thorough understanding and help in making informed decisions in data-driven applications."]},{"cell_type":"markdown","id":"9a660a46-dab3-439b-b4cb-6164534b1b09","metadata":{"id":"9a660a46-dab3-439b-b4cb-6164534b1b09"},"source":["### __9.1 Pandas Concatenate__\n","\n","- The __pd.concat()__ method combines DataFrames along rows or columns, preserving indices and columns.\n","- Specify axis=0 to concatenate along rows (vertical concatenation) or axis=1 to concatenate along columns (horizontal concatenation)."]},{"cell_type":"code","execution_count":null,"id":"004aca8e-fbaa-491d-bba2-c2a1da986f55","metadata":{"id":"004aca8e-fbaa-491d-bba2-c2a1da986f55","outputId":"3dad37ff-240f-4fa4-f783-ca9ebbb3aff9","tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["      A    B    C    D\n","0    A0   B0   C0   D0\n","1    A1   B1   C1   D1\n","2    A2   B2   C2   D2\n","3    A3   B3   C3   D3\n","4    A4   B4   C4   D4\n","5    A5   B5   C5   D5\n","6    A6   B6   C6   D6\n","7    A7   B7   C7   D7\n","8    A8   B8   C8   D8\n","9    A9   B9   C9   D9\n","10  A10  B10  C10  D10\n","11  A11  B11  C11  D11\n"]}],"source":["df1 = pd.DataFrame(\n","   {\n","       \"A\": [\"A0\", \"A1\", \"A2\", \"A3\"],\n","       \"B\": [\"B0\", \"B1\", \"B2\", \"B3\"],\n","       \"C\": [\"C0\", \"C1\", \"C2\", \"C3\"],\n","       \"D\": [\"D0\", \"D1\", \"D2\", \"D3\"],\n","   },\n","   index=[0, 1, 2, 3],\n",")\n","\n","df2 = pd.DataFrame(\n","   {\n","       \"A\": [\"A4\", \"A5\", \"A6\", \"A7\"],\n","       \"B\": [\"B4\", \"B5\", \"B6\", \"B7\"],\n","       \"C\": [\"C4\", \"C5\", \"C6\", \"C7\"],\n","       \"D\": [\"D4\", \"D5\", \"D6\", \"D7\"],\n","   },\n","   index=[4, 5, 6, 7],\n",")\n","\n","df3 = pd.DataFrame(\n","   {\n","       \"A\": [\"A8\", \"A9\", \"A10\", \"A11\"],\n","       \"B\": [\"B8\", \"B9\", \"B10\", \"B11\"],\n","       \"C\": [\"C8\", \"C9\", \"C10\", \"C11\"],\n","       \"D\": [\"D8\", \"D9\", \"D10\", \"D11\"],\n","   },\n","   index=[8, 9, 10, 11],\n",")\n","\n","frames = [df1, df2, df3]\n","Result = pd.concat(frames)\n","print(Result)"]},{"cell_type":"markdown","id":"360f2a13-9823-4e8d-8744-df1b38d653e5","metadata":{"id":"360f2a13-9823-4e8d-8744-df1b38d653e5"},"source":["The pictorial representation of the above output is as shown below:"]},{"cell_type":"markdown","id":"7082e7a5-ee71-457e-a8cb-4292640c3923","metadata":{"id":"7082e7a5-ee71-457e-a8cb-4292640c3923"},"source":["![link text](https://labcontent.simplicdn.net/data-content/content-assets/Data_and_AI/ADSP_Images/Lesson_09_Data_Wrangling/Concatenate.png)"]},{"cell_type":"markdown","id":"6b37b5df-80fb-45d7-812d-a44fb2f4c7c4","metadata":{"id":"6b37b5df-80fb-45d7-812d-a44fb2f4c7c4"},"source":["Here's another example illustrating concatenation along both the vertical and horizontal axes."]},{"cell_type":"code","execution_count":null,"id":"06d15115-eaa1-48ad-ac7a-956833601ca8","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"06d15115-eaa1-48ad-ac7a-956833601ca8","outputId":"f2ef6b19-ff4e-47f4-acba-0c5f5cb9d38a","tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Dataframe 1:\n","   A  B\n","0  1  4\n","1  2  5\n","2  3  6\n","\n","Dataframe 2:\n","   A   B\n","0  7  10\n","1  8  11\n","2  9  12\n","\n","Concatenated along rows:\n","   A   B\n","0  1   4\n","1  2   5\n","2  3   6\n","0  7  10\n","1  8  11\n","2  9  12\n","\n","Concatenated along columns:\n","   A  B  A   B\n","0  1  4  7  10\n","1  2  5  8  11\n","2  3  6  9  12\n"]}],"source":["import pandas as pd\n","\n","# Create two sample DataFrames\n","df1 = pd.DataFrame({'A': [1, 2, 3],\n","                    'B': [4, 5, 6]})\n","\n","df2 = pd.DataFrame({'A': [7, 8, 9],\n","                    'B': [10, 11, 12]})\n","\n","# Concatenate along rows (stack vertically)\n","Result_row = pd.concat([df1, df2], axis=0)\n","\n","# Concatenate along columns (stack horizontally)\n","Result_column = pd.concat([df1, df2], axis=1)\n","\n","print(\"\\nDataframe 1:\")\n","print(df1)\n","print(\"\\nDataframe 2:\")\n","print(df2)\n","\n","print(\"\\nConcatenated along rows:\")\n","print(Result_row)\n","\n","print(\"\\nConcatenated along columns:\")\n","print(Result_column)"]},{"cell_type":"markdown","id":"13f708ab-522d-48d2-9a98-f1bb46b50a0a","metadata":{"id":"13f708ab-522d-48d2-9a98-f1bb46b50a0a"},"source":["### __9.2 Pandas Merge DataFrames__\n","\n","- Utilize the  **pd.merge()** method to merge DataFrames based on specific keys or columns.\n","- Specify the join type in Pandas merge, which controls how rows from two DataFrames are combined.\n","- This ensures data alignment and prevents unintended outcomes.\n","- Choose the appropriate `how` parameter to specify the type of join.\n","- Specify the `on` parameter to indicate the column(s) to merge on.\n","\n","\n","\n","**Types of Pandas Join**\n","\n","There are various join logics available to merge Pandas DataFrames:\n","\n","- Full Outer Join: It merges all rows from both DataFrames, using NaN to fill in missing values when no match is found.\n","\n","- Inner Join: It combines matching rows from DataFrame 1 and DataFrame 2 based on a common key column.\n","\n","- Right Join: It retains all rows from the right DataFrame, merges on common keys, and fills missing values with NaN.\n","\n","- Left Join: It retains all rows from the left DataFrame, merging matching rows from the right and filling unmatched values with NaN.\n","\n","- Cross: It creates the cartesian product of the rows of both frames."]},{"cell_type":"code","execution_count":null,"id":"62000948-dd8d-4cf0-be84-914f46d1ba36","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"62000948-dd8d-4cf0-be84-914f46d1ba36","outputId":"86a4f53c-58f2-4566-e2a0-09300d5092e6","tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Dataframe 1:\n","  key1 key2   A   B\n","0   K0   K0  A0  B0\n","1   K0   K1  A1  B1\n","2   K1   K0  A2  B2\n","3   K2   K1  A3  B3\n","\n","Dataframe 2:\n","  key1 key2   C   D\n","0   K0   K0  C0  D0\n","1   K1   K0  C1  D1\n","2   K1   K0  C2  D2\n","3   K2   K0  C3  D3\n"]}],"source":["left = pd.DataFrame(\n","   {\n","      \"key1\": [\"K0\", \"K0\", \"K1\", \"K2\"],\n","      \"key2\": [\"K0\", \"K1\", \"K0\", \"K1\"],\n","      \"A\": [\"A0\", \"A1\", \"A2\", \"A3\"],\n","      \"B\": [\"B0\", \"B1\", \"B2\", \"B3\"],\n","   }\n",")\n","right = pd.DataFrame(\n","   {\n","      \"key1\": [\"K0\", \"K1\", \"K1\", \"K2\"],\n","      \"key2\": [\"K0\", \"K0\", \"K0\", \"K0\"],\n","      \"C\": [\"C0\", \"C1\", \"C2\", \"C3\"],\n","      \"D\": [\"D0\", \"D1\", \"D2\", \"D3\"],\n","   }\n",")\n","print(\"\\nDataframe 1:\")\n","print(left)\n","print(\"\\nDataframe 2:\")\n","print(right)"]},{"cell_type":"markdown","id":"93b2aedb-9813-4957-abc0-23dda5a4b17d","metadata":{"id":"93b2aedb-9813-4957-abc0-23dda5a4b17d"},"source":["**Full Outer Join**"]},{"cell_type":"code","execution_count":null,"id":"85a8fd44-3c14-4faf-9753-0ddeedc55925","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"85a8fd44-3c14-4faf-9753-0ddeedc55925","outputId":"95450f59-d81f-482e-b147-dbc2d98852d4","tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["  key1 key2    A    B    C    D\n","0   K0   K0   A0   B0   C0   D0\n","1   K0   K1   A1   B1  NaN  NaN\n","2   K1   K0   A2   B2   C1   D1\n","3   K1   K0   A2   B2   C2   D2\n","4   K2   K1   A3   B3  NaN  NaN\n","5   K2   K0  NaN  NaN   C3   D3\n"]}],"source":["Result = pd.merge(left, right, how=\"outer\", on=[\"key1\", \"key2\"])\n","print(Result)"]},{"cell_type":"markdown","id":"ef9ebdfa-5739-4e50-bf42-c6452004f5c0","metadata":{"id":"ef9ebdfa-5739-4e50-bf42-c6452004f5c0"},"source":["The pictorial representation of the above output is as shown below:"]},{"cell_type":"markdown","id":"7fa36117-f760-474e-ad8f-c96136818316","metadata":{"id":"7fa36117-f760-474e-ad8f-c96136818316","tags":[]},"source":["![link text](https://labcontent.simplicdn.net/data-content/content-assets/Data_and_AI/ADSP_Images/Lesson_09_Data_Wrangling/outer_merge.png)\n"]},{"cell_type":"markdown","id":"0dc145eb-7459-4e26-9808-dc887ebe8f19","metadata":{"id":"0dc145eb-7459-4e26-9808-dc887ebe8f19"},"source":["**Inner Join**"]},{"cell_type":"code","execution_count":null,"id":"d4a9928b-d4a6-4eba-8e90-c8e078aa6353","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d4a9928b-d4a6-4eba-8e90-c8e078aa6353","outputId":"7c2d3253-16d1-4721-cee1-489173124dae","tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["  key1 key2   A   B   C   D\n","0   K0   K0  A0  B0  C0  D0\n","1   K1   K0  A2  B2  C1  D1\n","2   K1   K0  A2  B2  C2  D2\n"]}],"source":["Result = pd.merge(left, right, how=\"inner\", on=[\"key1\", \"key2\"])\n","print(Result)"]},{"cell_type":"markdown","id":"dbc6f1fe-3774-46d2-bf2c-ff780e5822d2","metadata":{"id":"dbc6f1fe-3774-46d2-bf2c-ff780e5822d2"},"source":["The pictorial representation of the above output is as shown below:"]},{"cell_type":"markdown","id":"88e47df6-eadb-4e13-8037-ad9647aec58c","metadata":{"id":"88e47df6-eadb-4e13-8037-ad9647aec58c"},"source":["![link text](https://labcontent.simplicdn.net/data-content/content-assets/Data_and_AI/ADSP_Images/Lesson_09_Data_Wrangling/merge_inner.png)"]},{"cell_type":"markdown","id":"9fdb6397-7fea-444d-aca6-6ce223feeba1","metadata":{"id":"9fdb6397-7fea-444d-aca6-6ce223feeba1"},"source":["**Right Join**"]},{"cell_type":"code","execution_count":null,"id":"1493890b-2736-4b5a-923f-fda64961f310","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1493890b-2736-4b5a-923f-fda64961f310","outputId":"ea6047c4-9760-4a67-e6b2-b30a8497516a","tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["  key1 key2    A    B   C   D\n","0   K0   K0   A0   B0  C0  D0\n","1   K1   K0   A2   B2  C1  D1\n","2   K1   K0   A2   B2  C2  D2\n","3   K2   K0  NaN  NaN  C3  D3\n"]}],"source":["Result = pd.merge(left, right, how=\"right\", on=[\"key1\", \"key2\"])\n","print(Result)"]},{"cell_type":"markdown","id":"f637684a-a4f0-49d3-b90d-550ca000477b","metadata":{"id":"f637684a-a4f0-49d3-b90d-550ca000477b"},"source":["The pictorial representation of the above output is as shown below:"]},{"cell_type":"markdown","id":"b1509c03-075b-44f2-8b4f-69fc2b25e47c","metadata":{"id":"b1509c03-075b-44f2-8b4f-69fc2b25e47c"},"source":["![link text](https://labcontent.simplicdn.net/data-content/content-assets/Data_and_AI/ADSP_Images/Lesson_09_Data_Wrangling/merge_right.png)"]},{"cell_type":"markdown","id":"85138b91-2fa0-4f90-bac6-c778f2939854","metadata":{"id":"85138b91-2fa0-4f90-bac6-c778f2939854"},"source":["**Left Join**"]},{"cell_type":"code","execution_count":null,"id":"ffca37c3-ee9f-4b73-9a2f-06eadc005ad6","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ffca37c3-ee9f-4b73-9a2f-06eadc005ad6","outputId":"59418453-859f-447f-b8ae-72581a302b7d","tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["  key1 key2   A   B    C    D\n","0   K0   K0  A0  B0   C0   D0\n","1   K0   K1  A1  B1  NaN  NaN\n","2   K1   K0  A2  B2   C1   D1\n","3   K1   K0  A2  B2   C2   D2\n","4   K2   K1  A3  B3  NaN  NaN\n"]}],"source":["Result = pd.merge(left, right, how=\"left\", on=[\"key1\", \"key2\"])\n","print(Result)"]},{"cell_type":"markdown","id":"08141c76-43c2-4ec2-9f89-4711dd84d92c","metadata":{"id":"08141c76-43c2-4ec2-9f89-4711dd84d92c"},"source":["The pictorial representation of the above output is as shown below:"]},{"cell_type":"markdown","id":"5a2da1b4-6afb-4dc4-8a1f-4add8043766a","metadata":{"id":"5a2da1b4-6afb-4dc4-8a1f-4add8043766a"},"source":["![link text](https://labcontent.simplicdn.net/data-content/content-assets/Data_and_AI/ADSP_Images/Lesson_09_Data_Wrangling/merge_letf.png)"]},{"cell_type":"markdown","id":"89841db3-e351-4c66-8959-ce82465fbf9a","metadata":{"id":"89841db3-e351-4c66-8959-ce82465fbf9a","tags":[]},"source":["**Cross**"]},{"cell_type":"code","execution_count":null,"id":"e2810f86-88ed-48b3-8f53-380370cdb0fd","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e2810f86-88ed-48b3-8f53-380370cdb0fd","outputId":"7ad4d6a9-bddf-4a27-ff62-f41b89039bac","tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["   key1_x key2_x   A   B key1_y key2_y   C   D\n","0      K0     K0  A0  B0     K0     K0  C0  D0\n","1      K0     K0  A0  B0     K1     K0  C1  D1\n","2      K0     K0  A0  B0     K1     K0  C2  D2\n","3      K0     K0  A0  B0     K2     K0  C3  D3\n","4      K0     K1  A1  B1     K0     K0  C0  D0\n","5      K0     K1  A1  B1     K1     K0  C1  D1\n","6      K0     K1  A1  B1     K1     K0  C2  D2\n","7      K0     K1  A1  B1     K2     K0  C3  D3\n","8      K1     K0  A2  B2     K0     K0  C0  D0\n","9      K1     K0  A2  B2     K1     K0  C1  D1\n","10     K1     K0  A2  B2     K1     K0  C2  D2\n","11     K1     K0  A2  B2     K2     K0  C3  D3\n","12     K2     K1  A3  B3     K0     K0  C0  D0\n","13     K2     K1  A3  B3     K1     K0  C1  D1\n","14     K2     K1  A3  B3     K1     K0  C2  D2\n","15     K2     K1  A3  B3     K2     K0  C3  D3\n"]}],"source":["Result = pd.merge(left, right, how=\"cross\")\n","print(Result)"]},{"cell_type":"markdown","id":"d260fabd-018a-400c-94e0-c12cc3e961aa","metadata":{"id":"d260fabd-018a-400c-94e0-c12cc3e961aa"},"source":["The pictorial representation of the above output is as shown below:"]},{"cell_type":"markdown","id":"f7b88ebf-5a73-4519-8062-1f78c015ed4d","metadata":{"id":"f7b88ebf-5a73-4519-8062-1f78c015ed4d"},"source":["![link text](https://labcontent.simplicdn.net/data-content/content-assets/Data_and_AI/ADSP_Images/Lesson_09_Data_Wrangling/merge_cross.png)"]},{"cell_type":"markdown","id":"20e46ed0-fb3d-41bf-9707-3d3f84e3b2b8","metadata":{"id":"20e46ed0-fb3d-41bf-9707-3d3f84e3b2b8"},"source":["### __9.3 Pandas Join DataFrames__\n","\n","- Use the __join()__ method to join DataFrames based on their indices\n","- Specify the `how` parameter to determine the type of join, similar to __pd.merge()__\n","- Use the `on` parameter if joining on specific columns, or simply call __join()__ without parameters to perform a simple index-based join\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"54e53e3d-c797-4625-bd00-bb123e44c032","metadata":{"id":"54e53e3d-c797-4625-bd00-bb123e44c032","outputId":"c69e86bf-b8f3-4aee-8da2-620d275229d9","tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["    A   B key   C   D\n","0  A0  B0  K0  C0  D0\n","1  A1  B1  K1  C1  D1\n","2  A2  B2  K0  C0  D0\n","3  A3  B3  K1  C1  D1\n"]}],"source":["left = pd.DataFrame(\n","    {\n","        \"A\": [\"A0\", \"A1\", \"A2\", \"A3\"],\n","        \"B\": [\"B0\", \"B1\", \"B2\", \"B3\"],\n","        \"key\": [\"K0\", \"K1\", \"K0\", \"K1\"],\n","    }\n",")\n","right = pd.DataFrame({\"C\": [\"C0\", \"C1\"],\n","                      \"D\": [\"D0\", \"D1\"]},\n","                      index=[\"K0\", \"K1\"])\n","\n","Result = left.join(right, on=\"key\")\n","print(Result)"]},{"cell_type":"markdown","id":"c02e6757-b102-4f4e-b1a0-e89d62ddc1e9","metadata":{"id":"c02e6757-b102-4f4e-b1a0-e89d62ddc1e9"},"source":["The pictorial representation of the above output is as shown below:"]},{"cell_type":"markdown","id":"a935373f-0d5d-4978-aa87-e251784862c8","metadata":{"id":"a935373f-0d5d-4978-aa87-e251784862c8"},"source":["![link text](https://labcontent.simplicdn.net/data-content/content-assets/Data_and_AI/ADSP_Images/Lesson_09_Data_Wrangling/join.png)"]},{"cell_type":"markdown","id":"9b3783f5-c4a8-49bb-bafb-cd05c6b300a4","metadata":{"id":"9b3783f5-c4a8-49bb-bafb-cd05c6b300a4"},"source":["## __10. Aggregating Data__\n","\n","Aggregating data involves summarizing or grouping data based on specific criteria. This is useful for creating meaningful insights and reducing data dimensionality.\n","\n","- Common aggregation functions include average(mean), median, minimum(min), maximum(max), sum, standard deviation(std), variance(var), and count."]},{"cell_type":"code","execution_count":null,"id":"3fc6aad2-ff89-4048-b89e-f17113f2c22d","metadata":{"id":"3fc6aad2-ff89-4048-b89e-f17113f2c22d","outputId":"2cf67507-c0c5-4763-d2f1-3a2b798c3c44","tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Aggregated DataFrame:\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead tr th {\n","        text-align: left;\n","    }\n","\n","    .dataframe thead tr:last-of-type th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr>\n","      <th></th>\n","      <th colspan=\"8\" halign=\"left\">Value</th>\n","    </tr>\n","    <tr>\n","      <th></th>\n","      <th>mean</th>\n","      <th>median</th>\n","      <th>min</th>\n","      <th>max</th>\n","      <th>sum</th>\n","      <th>std</th>\n","      <th>var</th>\n","      <th>count</th>\n","    </tr>\n","    <tr>\n","      <th>Category</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>A</th>\n","      <td>20.0</td>\n","      <td>20.0</td>\n","      <td>10</td>\n","      <td>30</td>\n","      <td>60</td>\n","      <td>10.000000</td>\n","      <td>100.0</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>B</th>\n","      <td>20.0</td>\n","      <td>20.0</td>\n","      <td>15</td>\n","      <td>25</td>\n","      <td>40</td>\n","      <td>7.071068</td>\n","      <td>50.0</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         Value                                           \n","          mean median min max sum        std    var count\n","Category                                                 \n","A         20.0   20.0  10  30  60  10.000000  100.0     3\n","B         20.0   20.0  15  25  40   7.071068   50.0     2"]},"execution_count":86,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","\n","# Creating a DataFrame with a 'Category' column and a 'Value' column\n","data = {'Category': ['A', 'B', 'A', 'B', 'A'],\n","        'Value': [10, 15, 20, 25, 30]}\n","df = pd.DataFrame(data)\n","\n","# Grouping the DataFrame by 'Category' and calculating various aggregations\n","df_aggregated = df.groupby('Category').agg({\n","    'Value': ['mean', 'median', 'min', 'max', 'sum', 'std', 'var', 'count']\n","})\n","\n","# Displaying the aggregated DataFrame\n","print(\"Aggregated DataFrame:\")\n","df_aggregated"]},{"cell_type":"markdown","id":"e0ebf25b-787f-4abf-8b7b-e0df0be651ae","metadata":{"id":"e0ebf25b-787f-4abf-8b7b-e0df0be651ae"},"source":["## __11. Reshaping Data__\n","\n","Reshaping data includes pivoting, melting, or stacking data to achieve a structure suitable for specific analyses or visualizations.\n","\n","![link text](https://labcontent.simplicdn.net/data-content/content-assets/Data_and_AI/ADSP_Images/Lesson_09_Data_Wrangling/Reshaping_data.png)"]},{"cell_type":"code","execution_count":null,"id":"41c28961-e709-467d-9230-9122d6d36fa8","metadata":{"id":"41c28961-e709-467d-9230-9122d6d36fa8","outputId":"382ed561-b507-4d60-e0e1-87571db219ec"},"outputs":[{"name":"stdout","output_type":"stream","text":["Pivoted DataFrame:\n","Category     A   B\n","Date              \n","2022-01-01  10  15\n","2022-01-02  20  25\n"]}],"source":["import pandas as pd\n","\n","# Assuming you have a DataFrame 'df' with 'Date', 'Category', and 'Value' columns\n","# Adjust column names and DataFrame based on your actual data\n","\n","# DataFrame\n","df = pd.DataFrame({'Date': ['2022-01-01', '2022-01-01', '2022-01-02', '2022-01-02'],\n","                   'Category': ['A', 'B', 'A', 'B'],\n","                   'Value': [10, 15, 20, 25]})\n","\n","# Pivoting data for better analysis\n","df_pivoted = df.pivot_table(index='Date', columns='Category', values='Value', aggfunc='mean')\n","\n","# Displaying the pivoted DataFrame\n","print(\"Pivoted DataFrame:\")\n","print(df_pivoted)"]},{"cell_type":"markdown","id":"c8267d0e-9f4d-4616-83a5-7944877caea7","metadata":{"id":"c8267d0e-9f4d-4616-83a5-7944877caea7"},"source":["# __Assisted Practice__"]},{"cell_type":"markdown","id":"1a949a7b-888c-4ce4-ba1b-c1c7fa798a55","metadata":{"id":"1a949a7b-888c-4ce4-ba1b-c1c7fa798a55"},"source":["## __Problem Statement:__\n","\n","The complexity of the housing market can be overwhelming. For a data scientist at a real estate company, the responsibility lies in analyzing housing data to uncover insights into house prices. The goal is to comprehend the elements influencing house prices and the impact of various house features on their price. This understanding aids the company in navigating the housing market more effectively and making well-informed decisions when purchasing and selling houses."]},{"cell_type":"markdown","id":"58b44961-3afc-4323-9eef-7e0ac04c1eba","metadata":{"id":"58b44961-3afc-4323-9eef-7e0ac04c1eba"},"source":["## __Steps to Perform:__\n","\n","- Understand the structure of the dataset, the types of variables, and any obvious issues in the data\n","- Check for duplicate entries in the dataset and decide how to handle them\n","- Identify and handle missing values. Decide whether to fill them in or drop them based on the context\n","- Apply the necessary transformations to the variables. This could include scaling numerical variables or encoding categorical variables\n","- For continuous variables, consider creating bins to turn them into categorical variables. For example, you can bin the __YearBuilt__ feature into decades\n","- Identify outliers in the dataset and decide on a strategy to handle them. You can use a box plot to visualize outliers in features like __LotArea__ or __SalePrice__"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":5}